{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8624dfca",
   "metadata": {},
   "source": [
    "Create a dataset from 3 numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b7d0f",
   "metadata": {},
   "source": [
    "Import numpy file for each shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# circle = np.load(\"../data/circle/circle_data_preprocess.npy\")    # (N1, 128, 128)  # (N1, 128, 128)\n",
    "# square = np.load(\"../data/square/square_data_preprocess.npy\")    # (N2, 128, 128)\n",
    "# triangle = np.load(\"../data/mini_dataset/triangle/triangle_data_preprocess.npy\")# (N3, 128, 128)\n",
    "base_dir = \"D:/data_saxs_LPS/reduced_dataset\"\n",
    "\n",
    "path_circle = os.path.join(base_dir,\"circle/first_channel.npy\")\n",
    "path_square = os.path.join(base_dir,\"square/first_channel.npy\")\n",
    "path_triangle = os.path.join(base_dir,\"triangle/first_channel.npy\")\n",
    "\n",
    "\n",
    "\n",
    "# path_circle = \"D:/data_saxs_LPS/reduced_dataset/circle/circle_data_preprocess.npy\"\n",
    "# path_square = \"D:/data_saxs_LPS/reduced_dataset/square/square_data_preprocess.npy\"\n",
    "# path_triangle = \"D:/data_saxs_LPS/reduced_dataset/triangle/triangle_data_preprocess.npy\"\n",
    "\n",
    "circle = np.load(path_circle)\n",
    "square = np.load(path_square)    # (N2, 128, 128)\n",
    "triangle = np.load(path_triangle)# (N3, 128, 128\n",
    "\n",
    "# circle = np.load(\"D:/data_saxs_LPS/reduced_dataset/circle/first_channel.npy\")\n",
    "# square = np.load(\"D:/data_saxs_LPS/reduced_dataset/square/first_channel.npy\")    # (N2, 128, 128)\n",
    "# triangle = np.load(\"D:/data_saxs_LPS/reduced_dataset/triangle/first_channel.npy\")# (N3, 128, 128\n",
    "\n",
    "\n",
    "\n",
    "print(circle.shape)\n",
    "print(square.shape)\n",
    "print(triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aabc788",
   "metadata": {},
   "source": [
    "Create corresponding labels.\n",
    "Create 3 numpy array:\n",
    "- 1 filled with 0 for circles, the shape is `len(circle)`\n",
    "- 1 filled with 1 for squares, the shape is `len(square)`\n",
    "- 1 filled with 2 for triangles, the shape is `len(triangle)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_circle = np.zeros(len(circle), dtype=int)           # classe 0\n",
    "y_square = np.ones(len(square), dtype=int)            # classe 1\n",
    "y_triangle = np.full(len(triangle), 2, dtype=int) \n",
    "\n",
    "print(y_circle.shape)\n",
    "print(y_square.shape)\n",
    "print(y_triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d685a",
   "metadata": {},
   "source": [
    "Concatenante the 3 arrays to pass from shapes (x,) (y,) (z,) to (x+y+z,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952179f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y_circle, y_square, y_triangle], axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adbe023",
   "metadata": {},
   "source": [
    "Concatenate the 3 numpy array to pass from dimensions (x, 128, 128) (y, 128, 128) (y, 128, 128) to 1 array of shape (x+y+z,128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7508c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_before_resize = np.concatenate([circle, square, triangle], axis=0) \n",
    "print(X_before_resize.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bc7ff",
   "metadata": {},
   "source": [
    "Reduce images (Let the raw image, juste resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dcea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "def resize_with_padding(img, target_size=128):\n",
    "    h, w = img.shape\n",
    "    scale = target_size / max(h, w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    img_resized = resize(img, (new_h, new_w),\n",
    "                         order=1,\n",
    "                         preserve_range=True,\n",
    "                         anti_aliasing=True)\n",
    "    # padding pour obtenir un carré\n",
    "    pad_h = (target_size - new_h) // 2\n",
    "    pad_w = (target_size - new_w) // 2\n",
    "    padded = np.zeros((target_size, target_size), dtype=img_resized.dtype)\n",
    "    padded[pad_h:pad_h+new_h, pad_w:pad_w+new_w] = img_resized\n",
    "    return padded\n",
    "\n",
    "# Pour tout ton dataset (N,H,W)\n",
    "print(X_before_resize.shape)\n",
    "X = np.array([resize_with_padding(img) for img in X_before_resize])\n",
    "print(X.shape)  # (N,128,128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X[0,:, :],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ffbd1",
   "metadata": {},
   "source": [
    "Keras need data in the shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X = X[..., np.newaxis]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7291576",
   "metadata": {},
   "source": [
    "OPTIONAL: Set random seed to (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55594c7",
   "metadata": {},
   "source": [
    "Shuffle with scikit learn to avoid learning on blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(X, y, random_state=seed)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57706c0",
   "metadata": {},
   "source": [
    "Split dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose que X et y sont déjà construits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,         # 20% en test\n",
    "    random_state=seed,       # pour reproductibilité\n",
    "    stratify=y             # pour garder la proportion des classes\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247189ed",
   "metadata": {},
   "source": [
    "Create a CNN 2D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --- ton modèle ---\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    #layers.Conv2D(32, (3,3), activation='relu', input_shape=(1083,1035,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4891fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- entraînement ---\n",
    "history = model.fit(\n",
    "    X_train, y_train,          # tes données d'entraînement\n",
    "    epochs=20,                 # nombre d'epochs\n",
    "    batch_size=64,             # taille de batch\n",
    "    validation_split=0.2,      # fraction du train utilisée pour validation\n",
    "    verbose=1                  # affiche les métriques\n",
    ")\n",
    "\n",
    "# --- tracé des courbes de métriques ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927fc7a",
   "metadata": {},
   "source": [
    "Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- prédiction sur le jeu de test ---\n",
    "y_pred_proba = model.predict(X_test)              # probabilités (nb_images, 3)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)          # classes prédites (0,1,2)\n",
    "\n",
    "# --- accuracy ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy sur le jeu de test : {acc:.3f}\")\n",
    "\n",
    "# --- matrice de confusion ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(cm)\n",
    "\n",
    "# --- affichage joli ---\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['circle','square','triangle'],\n",
    "            yticklabels=['circle','square','triangle'])\n",
    "plt.xlabel('Prédit')\n",
    "plt.ylabel('Réel')\n",
    "plt.title(f'Matrice de confusion (Accuracy {acc:.2%})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model : ton modèle Keras\n",
    "def model_size_and_params(model, dtype_size=4):\n",
    "    params = model.count_params()\n",
    "    # approx size in bytes (float32 = 4 bytes)\n",
    "    size_bytes = params * dtype_size\n",
    "    size_mb = size_bytes / (1024**2)\n",
    "    return params, size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def file_size_mb(path):\n",
    "    \"\"\"Retourne la taille d’un fichier en MB\"\"\"\n",
    "    return os.path.getsize(path) / (1024 ** 2)\n",
    "\n",
    "circle_size   = file_size_mb(path_circle)\n",
    "square_size   = file_size_mb(path_square)\n",
    "triangle_size = file_size_mb(path_triangle)\n",
    "\n",
    "\n",
    "def measure_inference_time(model, input_shape, n_warmup=10, n_run=100):\n",
    "    # generate random input (batch size 1)\n",
    "    x = np.random.rand(1, *input_shape).astype(np.float32)\n",
    "    # warmup\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model.predict(x, verbose=0)\n",
    "    # timed runs\n",
    "    t0 = time.time()\n",
    "    for _ in range(n_run):\n",
    "        _ = model.predict(x, verbose=0)\n",
    "    t1 = time.time()\n",
    "    avg_ms = (t1 - t0) / n_run * 1000\n",
    "    return avg_ms\n",
    "\n",
    "print(f\"Taille circle:   {circle_size:.2f} MB\")\n",
    "print(f\"Taille square:   {square_size:.2f} MB\")\n",
    "print(f\"Taille triangle: {triangle_size:.2f} MB\")\n",
    "print(f\"Taille totale:   {circle_size + square_size + triangle_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume model, X_train, folder_path exist\n",
    "params, model_mb = model_size_and_params(model)\n",
    "print(\"Params:\", params)\n",
    "print(\"Model size (MB):\", model_mb)\n",
    "print(f\"Taille totale:   {circle_size + square_size + triangle_size:.2f} MB\")\n",
    "avg_infer_ms = measure_inference_time(model, X_train.shape[1:])\n",
    "print(\"Inference ms:\", avg_infer_ms)\n",
    "# training time demo (1 epoch)\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(X_train[:128], y_train[:128], epochs=1, batch_size=8, verbose=1)\n",
    "print(\"1 epoch time (s):\", time.time()-t0)\n",
    "import psutil, os\n",
    "print(\"Process RSS (MB):\", psutil.Process(os.getpid()).memory_info().rss / 1024**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe4eb7",
   "metadata": {},
   "source": [
    "For pre-processed data:   \n",
    "<pre>\n",
    "Params: 3705475\n",
    "Model size (MB): 14.135265350341797\n",
    "Taille totale:   230.25 MB\n",
    "Inference ms: 710.1784157752991\n",
    "16/16 ━━━━━━━━━━━━━━━━━━━━ 3s 148ms/step - accuracy: 0.8729 - loss: 0.3561\n",
    "1 epoch time (s): 3.1816084384918213\n",
    "Process RSS (MB): 1528.75390625\n",
    "</pre>\n",
    "---\n",
    "<pre>\n",
    "Params: 3705475\n",
    "Model size (MB): 14.135265350341797\n",
    "Taille totale:   230.25 MB\n",
    "Inference ms: 561.4975476264954\n",
    "16/16 ━━━━━━━━━━━━━━━━━━━━ 8s 182ms/step - accuracy: 0.3554 - loss: 1.4452\n",
    "1 epoch time (s): 8.540453910827637\n",
    "Process RSS (MB): 1283.8359375\n",
    "</pre>\n",
    "---\n",
    "---\n",
    "For raw data\n",
    "\n",
    "<pre>\n",
    "Params: 283187843\n",
    "Model size (MB): 1080.2758903503418\n",
    "Taille totale:   7876.23 MB\n",
    "Inference ms: 940.4475092887878\n",
    "16/16 ━━━━━━━━━━━━━━━━━━━━ 219s 11s/step - accuracy: 0.4024 - loss: 18972995584.0000\n",
    "1 epoch time (s): 232.40875720977783\n",
    "Process RSS (MB): 11297.3125\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donnees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
